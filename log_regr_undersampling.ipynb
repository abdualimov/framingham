{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Admission_train = pd.read_csv('Admission_train.csv')\n",
    "Admission_test = pd.read_csv('Admission_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Admission_train.drop(['Unnamed: 0', 'Serial No.'], axis = 1, inplace=True)\n",
    "Admission_test.drop(['Unnamed: 0', 'Serial No.'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Admission_train['Chance of Admit '] = Admission_train['Chance of Admit '].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "Admission_test['Chance of Admit '] = Admission_test['Chance of Admit '].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adm_train_cel_per = Admission_train['Chance of Admit ']\n",
    "Adm_train_per = Admission_train.drop(['Chance of Admit '], axis = 1)\n",
    "Adm_test_cel_per = Admission_test['Chance of Admit ']\n",
    "Adm_test_per = Admission_test.drop(['Chance of Admit '], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы не делать 100500 копипастов, создадим функцию print_logit_scores\n",
    "# которая будет обучать регрессию заданным способом и выводить разные метрики качества\n",
    "\n",
    "def print_logit_scores(Adm_train_per, Adm_train_cel_per, Adm_test_per, Adm_test_cel_per, model_type, weights):\n",
    "    \n",
    "    # data_train, target_train, data_test, target_test - это обучающие и тестовые данные\n",
    "    # model_type задает один из 3 типов обучения: 'n' - None, 'b' - balanced, 'w' - заданные пользователем веса\n",
    "    # w - вектор весов. Используется только для model_type = 'w'\n",
    "    \n",
    "    if (model_type == 'n'): # обучаем с равными весами\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight=None)    \n",
    "    elif (model_type == 'b'): # балансируем веса, как предлагают разработчики sklearn\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "    elif (model_type == 'w'): # балансируем веса самостоятельно\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight={0:weights[0], 1:weights[1]}) \n",
    "\n",
    "    # обучаем\n",
    "    model = lm.fit(Adm_train_per, Adm_train_cel_per.values.ravel()) \n",
    "\n",
    "    # сделаем prediction классов на всей тестовой выборке\n",
    "    target_pred = lm.predict(Adm_test_per)\n",
    "\n",
    "    # строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "    cnf_matrix = metrics.confusion_matrix(Adm_test_cel_per, target_pred)\n",
    "\n",
    "    TN = cnf_matrix[0,0] # True Negative\n",
    "    TP = cnf_matrix[1,1] # True Positive\n",
    "    FN = cnf_matrix[1,0] # False Negative\n",
    "    FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "    Ac = lm.score(Adm_test_per, Adm_test_cel_per)\n",
    "    Sens = TP/(TP+FN) \n",
    "    Sp = TN/(TN+FP)\n",
    "    P = TP/(TP+FP)\n",
    "    typeI = FP/(FP+TN)\n",
    "    typeII = FN/(FN+TP)\n",
    "    \n",
    "    print('Accuracy: ', Ac)\n",
    "    print('Sensitivity: ', Sens)\n",
    "    print('Specificity: ', Sp)\n",
    "    print('Precision: ', P)\n",
    "    print('Type I error rate: ', typeI)\n",
    "    print('Type II error rate: ', typeII)\n",
    "    \n",
    "    return [Ac,Sens,Sp,P,typeI,typeII] # возвращаем список метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91, 0.09])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share = Adm_test_cel_per.value_counts()\n",
    "w0 = share[1]/(share[0]+share[1])\n",
    "w = np.array([w0,1-w0])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.55555556, 0.54945055])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(Adm_test_cel_per) # считает количество вхождений 0 и 1 в y_train['TenYearCHD']\n",
    "w_b = Adm_test_per.shape[0]/ (2*np.bincount(Adm_test_cel_per))\n",
    "w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отношение интуитивных весов:  10.111111111111114\n",
      "отношение balanced весов:  10.11111111111111\n"
     ]
    }
   ],
   "source": [
    "# Давайте убедимся, что отношения весов действительно одинаковые\n",
    "# При этом бОльший по размеру класс (нулевой, то есть здоровые пациенты) имеет мЕньший вес\n",
    "print('отношение интуитивных весов: ', w[0]/w[1])\n",
    "print('отношение balanced весов: ', w_b[0]/w_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ручная балансировка по правилу balanced\n",
      "Accuracy:  0.78\n",
      "Sensitivity:  0.7802197802197802\n",
      "Specificity:  0.7777777777777778\n",
      "Precision:  0.9726027397260274\n",
      "Type I error rate:  0.2222222222222222\n",
      "Type II error rate:  0.21978021978021978\n",
      "\n",
      "\n",
      "встроенная балансировка по правилу balanced\n",
      "Accuracy:  0.78\n",
      "Sensitivity:  0.7802197802197802\n",
      "Specificity:  0.7777777777777778\n",
      "Precision:  0.9726027397260274\n",
      "Type I error rate:  0.2222222222222222\n",
      "Type II error rate:  0.21978021978021978\n",
      "\n",
      "\n",
      "без балансировки весов\n",
      "Accuracy:  0.91\n",
      "Sensitivity:  0.967032967032967\n",
      "Specificity:  0.3333333333333333\n",
      "Precision:  0.9361702127659575\n",
      "Type I error rate:  0.6666666666666666\n",
      "Type II error rate:  0.03296703296703297\n"
     ]
    }
   ],
   "source": [
    "# сравним \n",
    "print('ручная балансировка по правилу balanced')\n",
    "m1 = print_logit_scores(Adm_train_per, Adm_train_cel_per, Adm_test_per, Adm_test_cel_per, 'w', w_b) # ручная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('встроенная балансировка по правилу balanced')\n",
    "m2 = print_logit_scores(Adm_train_per, Adm_train_cel_per, Adm_test_per, Adm_test_cel_per, 'b', w) # встроенная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('без балансировки весов')\n",
    "m3 = print_logit_scores(Adm_train_per, Adm_train_cel_per, Adm_test_per, Adm_test_cel_per, 'n', w) # без балансировки весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# освежите в памяти, что показывает share и что значит share[1]\n",
    "# параметр ratio в RandomUnderSampler задается словарем: \n",
    "# 1: - желаемое количество объектов класса 1\n",
    "# 0: - желаемое количество объектов класса 0\n",
    "\n",
    "# задаем параметры выборки:\n",
    "sampler = RandomUnderSampler(sampling_strategy = {1: share[0], 0: share[0]})\n",
    "\n",
    "# сам unpersampling выполняется здесь:\n",
    "X_train_under_np, y_train_under_np = sampler.fit_sample(Adm_train_per.values, Adm_train_cel_per.values)\n",
    "\n",
    "# преобразуем в DataFrame, чтобы скормить логистической регрессии\n",
    "X_train_under = pd.DataFrame(X_train_under_np)\n",
    "y_train_under = pd.DataFrame(y_train_under_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.77\n",
      "Sensitivity:  0.7692307692307693\n",
      "Specificity:  0.7777777777777778\n",
      "Precision:  0.9722222222222222\n",
      "Type I error rate:  0.2222222222222222\n",
      "Type II error rate:  0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "# вычисляем качество модели с undersampling\n",
    "m_u = print_logit_scores(X_train_under, y_train_under, Adm_test_per, Adm_test_cel_per, 'n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.78\n",
      "Sensitivity:  0.7802197802197802\n",
      "Specificity:  0.7777777777777778\n",
      "Precision:  0.9726027397260274\n",
      "Type I error rate:  0.2222222222222222\n",
      "Type II error rate:  0.21978021978021978\n"
     ]
    }
   ],
   "source": [
    "# сравните результаты со встроенной балансировкой на всей обучающей выборке\n",
    "# как вы думаете, какой есть существенный недостаток у undersampling по сравнению с балансировкой весов?\n",
    "m2 = print_logit_scores(Adm_train_per, Adm_train_cel_per, Adm_test_per, Adm_test_cel_per, 'b', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
